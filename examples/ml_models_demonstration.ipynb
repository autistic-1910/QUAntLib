{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantLib Machine Learning Models Demonstration\n",
    "\n",
    "This notebook demonstrates the machine learning capabilities of the QuantLib library, showcasing:\n",
    "\n",
    "1. **LSTM Price Prediction** - Deep learning for time series forecasting\n",
    "2. **Reinforcement Learning Portfolio Optimization** - Adaptive asset allocation\n",
    "3. **Ensemble Risk Models** - Multi-model risk prediction with uncertainty\n",
    "\n",
    "Each model includes training, evaluation, and practical applications in quantitative finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Import our ML models\n",
    "from ml_training_models import (\n",
    "    LSTMPricePredictionModel,\n",
    "    PortfolioOptimizationRL,\n",
    "    EnsembleRiskModel\n",
    ")\n",
    "\n",
    "print('✓ All libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "First, let's generate realistic market data for our demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic market data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create date range\n",
    "dates = pd.date_range('2020-01-01', '2023-12-31', freq='D')\n",
    "n_days = len(dates)\n",
    "\n",
    "# Simulate correlated stock returns with realistic parameters\n",
    "mean_returns = [0.0008, 0.0006, 0.0007]  # ~20% annual return\n",
    "cov_matrix = [\n",
    "    [0.0004, 0.0001, 0.0002],  # AAPL\n",
    "    [0.0001, 0.0003, 0.0001],  # GOOGL\n",
    "    [0.0002, 0.0001, 0.0005]   # MSFT\n",
    "]\n",
    "\n",
    "returns = np.random.multivariate_normal(mean_returns, cov_matrix, n_days)\n",
    "\n",
    "# Generate price series\n",
    "initial_prices = [150, 2500, 300]  # Realistic starting prices\n",
    "prices = pd.DataFrame({\n",
    "    'AAPL': initial_prices[0] * np.cumprod(1 + returns[:, 0]),\n",
    "    'GOOGL': initial_prices[1] * np.cumprod(1 + returns[:, 1]),\n",
    "    'MSFT': initial_prices[2] * np.cumprod(1 + returns[:, 2])\n",
    "}, index=dates)\n",
    "\n",
    "# Add realistic volume data\n",
    "for col in prices.columns:\n",
    "    prices[f'{col}_volume'] = np.random.lognormal(15, 0.5, n_days)\n",
    "    prices[f'{col}_high'] = prices[col] * (1 + np.random.uniform(0, 0.02, n_days))\n",
    "    prices[f'{col}_low'] = prices[col] * (1 - np.random.uniform(0, 0.02, n_days))\n",
    "\n",
    "# Create OHLC data for AAPL (primary asset for LSTM)\n",
    "aapl_data = pd.DataFrame({\n",
    "    'close': prices['AAPL'],\n",
    "    'volume': prices['AAPL_volume'],\n",
    "    'high': prices['AAPL_high'],\n",
    "    'low': prices['AAPL_low']\n",
    "}, index=dates)\n",
    "\n",
    "print(f'Generated {len(prices)} days of market data')\n",
    "print(f'Date range: {dates[0].strftime(\"%Y-%m-%d\")} to {dates[-1].strftime(\"%Y-%m-%d\")}')\n",
    "print(f'Assets: {\", \".join(prices.columns[:3])}')\n",
    "\n",
    "# Display basic statistics\n",
    "print('\\nPrice Statistics:')\n",
    "for col in ['AAPL', 'GOOGL', 'MSFT']:\n",
    "    start_price = prices[col].iloc[0]\n",
    "    end_price = prices[col].iloc[-1]\n",
    "    total_return = (end_price / start_price - 1) * 100\n",
    "    print(f'{col}: ${start_price:.2f} → ${end_price:.2f} ({total_return:+.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Price evolution\n",
    "axes[0, 0].plot(prices.index, prices['AAPL'], label='AAPL', linewidth=2)\n",
    "axes[0, 0].plot(prices.index, prices['GOOGL']/10, label='GOOGL/10', linewidth=2)\n",
    "axes[0, 0].plot(prices.index, prices['MSFT'], label='MSFT', linewidth=2)\n",
    "axes[0, 0].set_title('Stock Price Evolution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Daily returns distribution\n",
    "returns_df = prices[['AAPL', 'GOOGL', 'MSFT']].pct_change().dropna()\n",
    "axes[0, 1].hist(returns_df['AAPL'], bins=50, alpha=0.7, label='AAPL')\n",
    "axes[0, 1].hist(returns_df['GOOGL'], bins=50, alpha=0.7, label='GOOGL')\n",
    "axes[0, 1].hist(returns_df['MSFT'], bins=50, alpha=0.7, label='MSFT')\n",
    "axes[0, 1].set_title('Daily Returns Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Daily Return')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling volatility\n",
    "rolling_vol = returns_df.rolling(30).std() * np.sqrt(252)\n",
    "axes[1, 0].plot(rolling_vol.index, rolling_vol['AAPL'], label='AAPL')\n",
    "axes[1, 0].plot(rolling_vol.index, rolling_vol['GOOGL'], label='GOOGL')\n",
    "axes[1, 0].plot(rolling_vol.index, rolling_vol['MSFT'], label='MSFT')\n",
    "axes[1, 0].set_title('30-Day Rolling Volatility (Annualized)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Volatility')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation heatmap\n",
    "corr_matrix = returns_df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Asset Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nData characteristics:')\n",
    "print(f'Average daily volatility: {returns_df.std().mean():.4f}')\n",
    "print(f'Average correlation: {corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].mean():.3f}')\n",
    "print(f'Sharpe ratios (assuming 2% risk-free rate):')\n",
    "for col in returns_df.columns:\n",
    "    annual_return = returns_df[col].mean() * 252\n",
    "    annual_vol = returns_df[col].std() * np.sqrt(252)\n",
    "    sharpe = (annual_return - 0.02) / annual_vol\n",
    "    print(f'  {col}: {sharpe:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LSTM Price Prediction Model\n",
    "\n",
    "Long Short-Term Memory (LSTM) networks are particularly well-suited for time series prediction due to their ability to capture long-term dependencies in sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TensorFlow is available\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "    print(f'✓ TensorFlow {tf.__version__} available')\n",
    "except ImportError:\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "    print('⚠️ TensorFlow not available - LSTM demonstration will be simulated')\n",
    "\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Initialize LSTM model\n",
    "    lstm_model = LSTMPricePredictionModel(\n",
    "        sequence_length=60,  # Use 60 days of history\n",
    "        features=['close', 'volume', 'high', 'low']\n",
    "    )\n",
    "    \n",
    "    # Split data for training and testing\n",
    "    train_size = int(len(aapl_data) * 0.8)\n",
    "    train_data = aapl_data.iloc[:train_size]\n",
    "    test_data = aapl_data.iloc[train_size:]\n",
    "    \n",
    "    print(f'Training data: {len(train_data)} days')\n",
    "    print(f'Testing data: {len(test_data)} days')\n",
    "    \n",
    "    # Train the model\n",
    "    print('\\nTraining LSTM model...')\n",
    "    training_results = lstm_model.train(train_data, validation_split=0.2)\n",
    "    \n",
    "    print('Training completed!')\n",
    "    print(f'Final training loss: {training_results[\"final_loss\"]:.6f}')\n",
    "    print(f'Final validation loss: {training_results[\"final_val_loss\"]:.6f}')\n",
    "    print(f'Final MAE: {training_results[\"final_mae\"]:.6f}')\n",
    "else:\n",
    "    # Simulate LSTM results for demonstration\n",
    "    print('Simulating LSTM training results...')\n",
    "    training_results = {\n",
    "        'final_loss': 0.001234,\n",
    "        'final_val_loss': 0.001456,\n",
    "        'final_mae': 0.028\n",
    "    }\n",
    "    print('Training completed (simulated)!')\n",
    "    print(f'Final training loss: {training_results[\"final_loss\"]:.6f}')\n",
    "    print(f'Final validation loss: {training_results[\"final_val_loss\"]:.6f}')\n",
    "    print(f'Final MAE: {training_results[\"final_mae\"]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and evaluate\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Make predictions for the next 30 days\n",
    "    prediction_input = aapl_data.iloc[-90:-30]  # Use 60 days before test period\n",
    "    predictions = lstm_model.predict(prediction_input, steps_ahead=30)\n",
    "    actual_prices = aapl_data['close'].iloc[-30:].values\n",
    "    \n",
    "    # Calculate prediction metrics\n",
    "    mae = np.mean(np.abs(predictions - actual_prices))\n",
    "    mape = np.mean(np.abs((predictions - actual_prices) / actual_prices)) * 100\n",
    "    rmse = np.sqrt(np.mean((predictions - actual_prices) ** 2))\n",
    "    \n",
    "    print(f'\\nPrediction Metrics (30-day forecast):')\n",
    "    print(f'MAE: ${mae:.2f}')\n",
    "    print(f'MAPE: {mape:.2f}%')\n",
    "    print(f'RMSE: ${rmse:.2f}')\n",
    "else:\n",
    "    # Simulate predictions\n",
    "    actual_prices = aapl_data['close'].iloc[-30:].values\n",
    "    # Add some realistic noise to actual prices for simulation\n",
    "    predictions = actual_prices + np.random.normal(0, 2, len(actual_prices))\n",
    "    \n",
    "    mae = np.mean(np.abs(predictions - actual_prices))\n",
    "    mape = np.mean(np.abs((predictions - actual_prices) / actual_prices)) * 100\n",
    "    rmse = np.sqrt(np.mean((predictions - actual_prices) ** 2))\n",
    "    \n",
    "    print(f'\\nPrediction Metrics (30-day forecast, simulated):')\n",
    "    print(f'MAE: ${mae:.2f}')\n",
    "    print(f'MAPE: {mape:.2f}%')\n",
    "    print(f'RMSE: ${rmse:.2f}')\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot predictions vs actual\n",
    "test_dates = aapl_data.index[-30:]\n",
    "axes[0].plot(test_dates, actual_prices, label='Actual Prices', linewidth=2, color='blue')\n",
    "axes[0].plot(test_dates, predictions, label='LSTM Predictions', linewidth=2, color='red', linestyle='--')\n",
    "axes[0].fill_between(test_dates, predictions - rmse, predictions + rmse, \n",
    "                     alpha=0.3, color='red', label=f'±RMSE (${rmse:.2f})')\n",
    "axes[0].set_title('LSTM Price Predictions vs Actual Prices', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot prediction errors\n",
    "errors = predictions - actual_prices\n",
    "axes[1].bar(range(len(errors)), errors, alpha=0.7, \n",
    "           color=['red' if e > 0 else 'green' for e in errors])\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "axes[1].set_title('Prediction Errors by Day', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Day')\n",
    "axes[1].set_ylabel('Error ($)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show sample predictions\n",
    "print('\\nSample Predictions:')\n",
    "for i in range(0, len(predictions), 5):\n",
    "    if i < len(predictions):\n",
    "        error_pct = abs(predictions[i] - actual_prices[i]) / actual_prices[i] * 100\n",
    "        print(f'Day {i+1:2d}: Predicted ${predictions[i]:6.2f}, Actual ${actual_prices[i]:6.2f}, Error: {error_pct:4.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reinforcement Learning Portfolio Optimization\n",
    "\n",
    "This RL agent learns optimal portfolio allocations by maximizing risk-adjusted returns through trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RL portfolio optimizer\n",
    "assets = ['AAPL', 'GOOGL', 'MSFT']\n",
    "rl_optimizer = PortfolioOptimizationRL(assets, lookback_window=30)\n",
    "\n",
    "print('Training Reinforcement Learning Portfolio Optimizer...')\n",
    "print(f'Assets: {\", \".join(assets)}')\n",
    "print(f'Lookback window: {rl_optimizer.lookback_window} days')\n",
    "\n",
    "# Train the RL agent\n",
    "training_data = prices[assets].iloc[:-100]  # Leave last 100 days for testing\n",
    "rl_results = rl_optimizer.train(training_data, episodes=1000)\n",
    "\n",
    "print('\\nRL Training Results:')\n",
    "print(f'Final episode reward: {rl_results[\"final_reward\"]:.4f}')\n",
    "print(f'Average reward (last 100 episodes): {rl_results[\"average_reward\"]:.4f}')\n",
    "print(f'Number of states learned: {rl_results[\"total_states\"]}')\n",
    "print(f'Final exploration rate: {rl_optimizer.epsilon:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained RL agent\n",
    "test_period = prices[assets].iloc[-100:]\n",
    "\n",
    "# Get allocations for different market conditions\n",
    "allocations_history = []\n",
    "dates_history = []\n",
    "\n",
    "for i in range(30, len(test_period), 10):  # Every 10 days\n",
    "    current_data = test_period.iloc[:i]\n",
    "    allocation = rl_optimizer.get_allocation(current_data)\n",
    "    allocations_history.append(allocation)\n",
    "    dates_history.append(test_period.index[i])\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "allocations_df = pd.DataFrame(allocations_history, \n",
    "                             columns=assets, \n",
    "                             index=dates_history)\n",
    "\n",
    "print('Portfolio Allocations Over Time:')\n",
    "print(allocations_df.round(3))\n",
    "\n",
    "# Calculate portfolio performance\n",
    "returns_data = test_period.pct_change().dropna()\n",
    "\n",
    "# Compare RL portfolio vs equal weight and individual assets\n",
    "final_allocation = rl_optimizer.get_allocation(test_period)\n",
    "equal_weight = [1/len(assets)] * len(assets)\n",
    "\n",
    "print(f'\\nFinal Optimal Allocation:')\n",
    "for asset, weight in zip(assets, final_allocation):\n",
    "    print(f'{asset}: {weight:.1%}')\n",
    "\n",
    "print(f'\\nEqual Weight Allocation:')\n",
    "for asset, weight in zip(assets, equal_weight):\n",
    "    print(f'{asset}: {weight:.1%}')\n",
    "\n",
    "# Calculate performance metrics\n",
    "rl_portfolio_returns = (returns_data * final_allocation).sum(axis=1)\n",
    "eq_portfolio_returns = (returns_data * equal_weight).sum(axis=1)\n",
    "\n",
    "def calculate_metrics(returns):\n",
    "    annual_return = returns.mean() * 252\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    sharpe = annual_return / annual_vol if annual_vol > 0 else 0\n",
    "    max_dd = ((1 + returns).cumprod() / (1 + returns).cumprod().expanding().max() - 1).min()\n",
    "    return annual_return, annual_vol, sharpe, max_dd\n",
    "\n",
    "rl_metrics = calculate_metrics(rl_portfolio_returns)\n",
    "eq_metrics = calculate_metrics(eq_portfolio_returns)\n",
    "\n",
    "print('\\nPerformance Comparison:')\n",
    "print(f'{\"\".ljust(20)} {\"RL Portfolio\":>12} {\"Equal Weight\":>12}')\n",
    "print('-' * 45)\n",
    "print(f'Annual Return      {rl_metrics[0]:>11.1%} {eq_metrics[0]:>11.1%}')\n",
    "print(f'Annual Volatility  {rl_metrics[1]:>11.1%} {eq_metrics[1]:>11.1%}')\n",
    "print(f'Sharpe Ratio       {rl_metrics[2]:>11.2f} {eq_metrics[2]:>11.2f}')\n",
    "print(f'Max Drawdown       {rl_metrics[3]:>11.1%} {eq_metrics[3]:>11.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RL portfolio optimization results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Portfolio allocation over time\n",
    "allocations_df.plot(kind='area', stacked=True, ax=axes[0, 0], alpha=0.7)\n",
    "axes[0, 0].set_title('RL Portfolio Allocation Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Allocation')\n",
    "axes[0, 0].legend(title='Assets')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative returns comparison\n",
    "rl_cumulative = (1 + rl_portfolio_returns).cumprod()\n",
    "eq_cumulative = (1 + eq_portfolio_returns).cumprod()\n",
    "\n",
    "axes[0, 1].plot(rl_cumulative.index, rl_cumulative, label='RL Portfolio', linewidth=2)\n",
    "axes[0, 1].plot(eq_cumulative.index, eq_cumulative, label='Equal Weight', linewidth=2)\n",
    "\n",
    "# Add individual asset performance\n",
    "for asset in assets:\n",
    "    asset_cumulative = (1 + returns_data[asset]).cumprod()\n",
    "    axes[0, 1].plot(asset_cumulative.index, asset_cumulative, \n",
    "                   label=asset, alpha=0.6, linestyle='--')\n",
    "\n",
    "axes[0, 1].set_title('Cumulative Returns Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Cumulative Return')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling Sharpe ratio\n",
    "window = 20\n",
    "rl_rolling_sharpe = rl_portfolio_returns.rolling(window).mean() / rl_portfolio_returns.rolling(window).std() * np.sqrt(252)\n",
    "eq_rolling_sharpe = eq_portfolio_returns.rolling(window).mean() / eq_portfolio_returns.rolling(window).std() * np.sqrt(252)\n",
    "\n",
    "axes[1, 0].plot(rl_rolling_sharpe.index, rl_rolling_sharpe, label='RL Portfolio', linewidth=2)\n",
    "axes[1, 0].plot(eq_rolling_sharpe.index, eq_rolling_sharpe, label='Equal Weight', linewidth=2)\n",
    "axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "axes[1, 0].set_title(f'{window}-Day Rolling Sharpe Ratio', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Sharpe Ratio')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Risk-return scatter\n",
    "portfolio_data = {\n",
    "    'RL Portfolio': rl_metrics,\n",
    "    'Equal Weight': eq_metrics\n",
    "}\n",
    "\n",
    "# Add individual assets\n",
    "for asset in assets:\n",
    "    asset_metrics = calculate_metrics(returns_data[asset])\n",
    "    portfolio_data[asset] = asset_metrics\n",
    "\n",
    "for name, (ret, vol, sharpe, dd) in portfolio_data.items():\n",
    "    color = 'red' if name == 'RL Portfolio' else 'blue' if name == 'Equal Weight' else 'gray'\n",
    "    size = 100 if name in ['RL Portfolio', 'Equal Weight'] else 60\n",
    "    axes[1, 1].scatter(vol, ret, s=size, alpha=0.7, label=name, c=color)\n",
    "\n",
    "axes[1, 1].set_title('Risk-Return Profile', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Annual Volatility')\n",
    "axes[1, 1].set_ylabel('Annual Return')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensemble Risk Prediction Model\n",
    "\n",
    "The ensemble model combines multiple machine learning algorithms to predict market risk with uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if scikit-learn is available\n",
    "try:\n",
    "    import sklearn\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(f'✓ Scikit-learn {sklearn.__version__} available')\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print('⚠️ Scikit-learn not available - Ensemble model demonstration will be simulated')\n",
    "\n",
    "if SKLEARN_AVAILABLE:\n",
    "    # Initialize ensemble risk model\n",
    "    risk_model = EnsembleRiskModel()\n",
    "    \n",
    "    # Train on historical data\n",
    "    train_data = prices[assets].iloc[:-100]\n",
    "    \n",
    "    print('Training Ensemble Risk Model...')\n",
    "    print(f'Training data: {len(train_data)} days')\n",
    "    print(f'Assets: {\", \".join(assets)}')\n",
    "    \n",
    "    try:\n",
    "        risk_results = risk_model.train(train_data)\n",
    "        \n",
    "        print('\\nEnsemble Training Results:')\n",
    "        for model_name, accuracy in risk_results.items():\n",
    "            print(f'{model_name}: {accuracy:.3f}')\n",
    "            \n",
    "        training_success = True\n",
    "    except Exception as e:\n",
    "        print(f'Training failed: {e}')\n",
    "        training_success = False\n",
    "else:\n",
    "    # Simulate ensemble results\n",
    "    print('Simulating Ensemble Risk Model training...')\n",
    "    risk_results = {\n",
    "        'random_forest_accuracy': 0.742,\n",
    "        'gradient_boost_accuracy': 0.758,\n",
    "        'svm_accuracy': 0.695,\n",
    "        'logistic_accuracy': 0.681,\n",
    "        'ensemble_accuracy': 0.773\n",
    "    }\n",
    "    \n",
    "    print('\\nEnsemble Training Results (simulated):')\n",
    "    for model_name, accuracy in risk_results.items():\n",
    "        print(f'{model_name}: {accuracy:.3f}')\n",
    "        \n",
    "    training_success = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make risk predictions\n",
    "if training_success:\n",
    "    test_data = prices[assets].iloc[-100:]\n",
    "    \n",
    "    # Get risk predictions for different time periods\n",
    "    risk_predictions = []\n",
    "    prediction_dates = []\n",
    "    \n",
    "    for i in range(50, len(test_data), 10):  # Every 10 days\n",
    "        current_data = test_data.iloc[:i]\n",
    "        \n",
    "        if SKLEARN_AVAILABLE and hasattr(risk_model, 'is_trained') and risk_model.is_trained:\n",
    "            try:\n",
    "                prediction = risk_model.predict_risk(current_data)\n",
    "                risk_predictions.append(prediction)\n",
    "                prediction_dates.append(test_data.index[i])\n",
    "            except Exception as e:\n",
    "                print(f'Prediction failed for date {test_data.index[i]}: {e}')\n",
    "        else:\n",
    "            # Simulate risk predictions\n",
    "            # Base risk on actual market volatility\n",
    "            recent_returns = current_data.pct_change().dropna()\n",
    "            portfolio_vol = recent_returns.mean(axis=1).rolling(20).std().iloc[-1]\n",
    "            \n",
    "            # Convert volatility to risk probability\n",
    "            risk_prob = min(0.9, max(0.1, portfolio_vol * 50))\n",
    "            \n",
    "            prediction = {\n",
    "                'risk_probability': risk_prob,\n",
    "                'uncertainty': np.random.uniform(0.05, 0.15),\n",
    "                'individual_predictions': {\n",
    "                    'random_forest': risk_prob + np.random.normal(0, 0.05),\n",
    "                    'gradient_boost': risk_prob + np.random.normal(0, 0.05),\n",
    "                    'svm': risk_prob + np.random.normal(0, 0.08),\n",
    "                    'logistic': risk_prob + np.random.normal(0, 0.06)\n",
    "                },\n",
    "                'risk_level': 'HIGH' if risk_prob > 0.6 else 'LOW'\n",
    "            }\n",
    "            risk_predictions.append(prediction)\n",
    "            prediction_dates.append(test_data.index[i])\n",
    "    \n",
    "    print(f'\\nGenerated {len(risk_predictions)} risk predictions')\n",
    "    \n",
    "    # Show recent predictions\n",
    "    print('\\nRecent Risk Predictions:')\n",
    "    for i, (date, pred) in enumerate(zip(prediction_dates[-5:], risk_predictions[-5:])):\n",
    "        print(f'{date.strftime(\"%Y-%m-%d\")}: {pred[\"risk_level\"]} ({pred[\"risk_probability\"]:.1%}, uncertainty: {pred[\"uncertainty\"]:.3f})')\n",
    "    \n",
    "    # Calculate actual risk (realized volatility)\n",
    "    actual_risk = []\n",
    "    for date in prediction_dates:\n",
    "        # Look forward 10 days to calculate realized risk\n",
    "        date_idx = test_data.index.get_loc(date)\n",
    "        if date_idx + 10 < len(test_data):\n",
    "            future_returns = test_data.iloc[date_idx:date_idx+10].pct_change().dropna()\n",
    "            realized_vol = future_returns.mean(axis=1).std()\n",
    "            actual_risk.append(1 if realized_vol > 0.02 else 0)  # High risk threshold\n",
    "        else:\n",
    "            actual_risk.append(np.nan)\n",
    "    \n",
    "    # Remove NaN values\n",
    "    valid_indices = ~np.isnan(actual_risk)\n",
    "    actual_risk = np.array(actual_risk)[valid_indices]\n",
    "    predicted_risk = [pred['risk_probability'] for pred in risk_predictions]\n",
    "    predicted_risk = np.array(predicted_risk)[valid_indices]\n",
    "    \n",
    "    if len(actual_risk) > 0:\n",
    "        # Calculate prediction accuracy\n",
    "        predicted_binary = (predicted_risk > 0.6).astype(int)\n",
    "        accuracy = np.mean(predicted_binary == actual_risk)\n",
    "        \n",
    "        print(f'\\nRisk Prediction Accuracy: {accuracy:.1%}')\n",
    "        print(f'Predicted high risk periods: {np.sum(predicted_binary)} / {len(predicted_binary)}')\n",
    "        print(f'Actual high risk periods: {np.sum(actual_risk)} / {len(actual_risk)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize risk prediction results\n",
    "if training_success and len(risk_predictions) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Risk probability over time\n",
    "    risk_probs = [pred['risk_probability'] for pred in risk_predictions]\n",
    "    uncertainties = [pred['uncertainty'] for pred in risk_predictions]\n",
    "    \n",
    "    axes[0, 0].plot(prediction_dates, risk_probs, label='Risk Probability', linewidth=2, color='red')\n",
    "    axes[0, 0].fill_between(prediction_dates, \n",
    "                           np.array(risk_probs) - np.array(uncertainties),\n",
    "                           np.array(risk_probs) + np.array(uncertainties),\n",
    "                           alpha=0.3, color='red', label='Uncertainty Band')\n",
    "    axes[0, 0].axhline(y=0.6, color='orange', linestyle='--', label='High Risk Threshold')\n",
    "    axes[0, 0].set_title('Risk Probability Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Risk Probability')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Model agreement (uncertainty)\n",
    "    axes[0, 1].plot(prediction_dates, uncertainties, linewidth=2, color='purple')\n",
    "    axes[0, 1].set_title('Model Uncertainty (Disagreement)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Uncertainty')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Individual model predictions for latest prediction\n",
    "    if risk_predictions:\n",
    "        latest_pred = risk_predictions[-1]\n",
    "        model_names = list(latest_pred['individual_predictions'].keys())\n",
    "        model_preds = list(latest_pred['individual_predictions'].values())\n",
    "        \n",
    "        bars = axes[1, 0].bar(model_names, model_preds, alpha=0.7)\n",
    "        axes[1, 0].axhline(y=latest_pred['risk_probability'], color='red', \n",
    "                          linestyle='-', linewidth=2, label='Ensemble Prediction')\n",
    "        axes[1, 0].axhline(y=0.6, color='orange', linestyle='--', label='High Risk Threshold')\n",
    "        axes[1, 0].set_title('Individual Model Predictions (Latest)', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_ylabel('Risk Probability')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Risk vs actual market volatility\n",
    "    if len(actual_risk) > 0:\n",
    "        valid_dates = np.array(prediction_dates)[valid_indices]\n",
    "        \n",
    "        axes[1, 1].scatter(predicted_risk, actual_risk, alpha=0.7, s=60)\n",
    "        axes[1, 1].plot([0, 1], [0, 1], 'r--', alpha=0.8, label='Perfect Prediction')\n",
    "        axes[1, 1].axvline(x=0.6, color='orange', linestyle='--', alpha=0.7, label='Risk Threshold')\n",
    "        axes[1, 1].axhline(y=0.5, color='gray', linestyle='-', alpha=0.5)\n",
    "        axes[1, 1].set_title('Predicted vs Actual Risk', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Predicted Risk Probability')\n",
    "        axes[1, 1].set_ylabel('Actual Risk (Binary)')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print model performance summary\n",
    "    print('\\n' + '='*60)\n",
    "    print('ENSEMBLE RISK MODEL SUMMARY')\n",
    "    print('='*60)\n",
    "    \n",
    "    if 'ensemble_accuracy' in risk_results:\n",
    "        print(f'Training Accuracy: {risk_results[\"ensemble_accuracy\"]:.1%}')\n",
    "    \n",
    "    if len(actual_risk) > 0:\n",
    "        print(f'Prediction Accuracy: {accuracy:.1%}')\n",
    "    \n",
    "    print(f'Average Risk Probability: {np.mean(risk_probs):.1%}')\n",
    "    print(f'Average Model Uncertainty: {np.mean(uncertainties):.3f}')\n",
    "    \n",
    "    high_risk_periods = sum(1 for pred in risk_predictions if pred['risk_level'] == 'HIGH')\n",
    "    print(f'High Risk Periods Identified: {high_risk_periods} / {len(risk_predictions)} ({high_risk_periods/len(risk_predictions):.1%})')\n",
    "else:\n",
    "    print('Risk prediction visualization skipped due to training failure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "This demonstration showcases the power of machine learning in quantitative finance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('QUANTLIB ML MODELS - SUMMARY OF RESULTS')\n",
    "print('='*80)\n",
    "\n",
    "print('1. LSTM PRICE PREDICTION:')\n",
    "print('   • Demonstrates deep learning for time series forecasting')\n",
    "if TENSORFLOW_AVAILABLE and 'final_mae' in training_results:\n",
    "    print(f'   • Achieved MAE of {training_results[\"final_mae\"]:.4f} on training data')\n",
    "if 'mape' in locals():\n",
    "    print(f'   • Prediction accuracy: {mape:.1f}% MAPE on test data')\n",
    "print('   • Can be integrated into trading strategies for signal generation')\n",
    "print('   • Useful for short-term price forecasting and trend analysis')\n",
    "\n",
    "print('2. REINFORCEMENT LEARNING PORTFOLIO OPTIMIZATION:')\n",
    "print('   • Learns optimal asset allocation through trial and error')\n",
    "if 'rl_results' in locals():\n",
    "    print(f'   • Learned {rl_results[\"total_states\"]} different market states')\n",
    "    print(f'   • Final training reward: {rl_results[\"final_reward\"]:.4f}')\n",
    "if 'rl_metrics' in locals() and 'eq_metrics' in locals():\n",
    "    print(f'   • RL Portfolio Sharpe: {rl_metrics[2]:.2f} vs Equal Weight: {eq_metrics[2]:.2f}')\n",
    "    print(f'   • RL Portfolio Return: {rl_metrics[0]:.1%} vs Equal Weight: {eq_metrics[0]:.1%}')\n",
    "print('   • Adapts to changing market conditions automatically')\n",
    "print('   • Balances risk and return through reward function optimization')\n",
    "\n",
    "print('3. ENSEMBLE RISK PREDICTION:')\n",
    "print('   • Combines multiple ML models for robust risk assessment')\n",
    "if 'risk_results' in locals() and 'ensemble_accuracy' in risk_results:\n",
    "    print(f'   • Training accuracy: {risk_results[\"ensemble_accuracy\"]:.1%}')\n",
    "if 'accuracy' in locals():\n",
    "    print(f'   • Prediction accuracy: {accuracy:.1%}')\n",
    "if 'uncertainties' in locals():\n",
    "    print(f'   • Average model uncertainty: {np.mean(uncertainties):.3f}')\n",
    "print('   • Provides uncertainty quantification for decision making')\n",
    "print('   • Helps identify periods of elevated market risk')\n",
    "\n",
    "print('KEY BENEFITS OF ML IN QUANTITATIVE FINANCE:')\n",
    "print('\n",
    "• ADAPTABILITY: Models learn from new data and adapt to market changes\n",
    "• PATTERN RECOGNITION: Identify complex, non-linear relationships\n",
    "• AUTOMATION: Reduce manual intervention in trading decisions\n",
    "• RISK MANAGEMENT: Better prediction and quantification of risks\n",
    "• DIVERSIFICATION: Multiple models reduce single-point-of-failure\n",
    "• SCALABILITY: Handle large datasets and multiple assets efficiently')\n",
    "\n",
    "print('PRACTICAL APPLICATIONS:')\n",
    "print('\n",
    "• Algorithmic Trading: Use LSTM predictions for entry/exit signals\n",
    "• Portfolio Management: RL optimization for dynamic rebalancing\n",
    "• Risk Control: Ensemble models for position sizing and stop-losses\n",
    "• Market Making: Predict short-term price movements for spreads\n",
    "• Stress Testing: Simulate various market scenarios with ML models\n",
    "• Factor Investing: Identify and exploit market inefficiencies')\n",
    "\n",
    "print('NEXT STEPS FOR IMPLEMENTATION:')\n",
    "print('\n",
    "1. Data Pipeline: Set up real-time data feeds and preprocessing\n",
    "2. Model Training: Implement walk-forward validation and retraining\n",
    "3. Backtesting: Integrate models with QuantLib backtesting framework\n",
    "4. Risk Management: Add position limits and drawdown controls\n",
    "5. Live Trading: Deploy models with paper trading first\n",
    "6. Monitoring: Track model performance and drift detection')\n",
    "\n",
    "print('='*80)\n",
    "print('For more information, see the QuantLib documentation and examples.')\n",
    "print('='*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}